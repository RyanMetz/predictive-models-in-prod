{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport pmip.feature_engineering\n",
    "%aimport pmip.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pmip.data import pickle_to_fs\n",
    "from pmip.feature_engineering import TextSelector, NumberSelector, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DATA_DIR=os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-training-20190112.ipynb',\n",
       " 'Youtube03-LMFAO.csv',\n",
       " 'Youtube04-Eminem.csv',\n",
       " 'Youtube05-Shakira.csv',\n",
       " 'Youtube02-KatyPerry.csv',\n",
       " 'model.pkl',\n",
       " '__MACOSX',\n",
       " 'model-training-20190112.html',\n",
       " 'YouTube-Spam-Collection-v1.zip',\n",
       " 'Youtube01-Psy.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_files = os.listdir(DATA_DIR)\n",
    "training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>z12cydggrzyesrklw23qwzexerqavj11e</td>\n",
       "      <td>monkey moments</td>\n",
       "      <td>2015-05-27T09:24:10.239000</td>\n",
       "      <td>i love this song thumsb up to you﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>LneaDw26bFvnMp5q__XiHBvyky8sw2uF9b-ZfDZi2to</td>\n",
       "      <td>WeTheDopeSquad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WATCH MY VIDEOS AND SUBSCRIBE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09T17:34:07.052000</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>z12pd3wq0p3wzzt5p04cd33pwnrreduadn40k</td>\n",
       "      <td>Brianna Reed</td>\n",
       "      <td>2015-05-25T03:02:02.615000</td>\n",
       "      <td>I LOVE YOUR SONGS﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>_2viQ_Qnc6_fgKR1W7-k1lbVURi8hVbMlQAMSOCSnyk</td>\n",
       "      <td>ThirdDegr3e</td>\n",
       "      <td>2013-07-13T20:48:22.967000</td>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>z12hvvki4xite3sjl04cfp34wxy0fr0qjgs</td>\n",
       "      <td>latisha garcia</td>\n",
       "      <td>2015-03-09T00:33:08.463000</td>\n",
       "      <td>Check out this playlist on YouTube: I tried﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>z121i1eqppzph3eod04cixfgwknydnfzq3k</td>\n",
       "      <td>railn j sander</td>\n",
       "      <td>2015-05-26T05:32:15.041000</td>\n",
       "      <td>I guss this song is one of my worst fears in l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>LneaDw26bFvv8RbyHRBDnA-4Bb1lhF9UlpzJf_5FkWM</td>\n",
       "      <td>이 정훈</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This great Warning will happen soon. ,0\\nLneaD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>z13ax5sicvvxsx3lx23vuf45tye4etl1g</td>\n",
       "      <td>Kasia Hill</td>\n",
       "      <td>2014-09-06T02:44:43</td>\n",
       "      <td>http://shhort.com/a?r=G8iX5cTKd﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>z135drnwswvsgvkyq04cfjh4xpb3cn2hugg</td>\n",
       "      <td>Sam Klein</td>\n",
       "      <td>2014-08-31T03:52:29</td>\n",
       "      <td>She named the tiger Kitty Purry  No, seriously...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID          AUTHOR  \\\n",
       "904             z12cydggrzyesrklw23qwzexerqavj11e  monkey moments   \n",
       "557   LneaDw26bFvnMp5q__XiHBvyky8sw2uF9b-ZfDZi2to  WeTheDopeSquad   \n",
       "1146  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY     Lizzy Molly   \n",
       "72          z12pd3wq0p3wzzt5p04cd33pwnrreduadn40k    Brianna Reed   \n",
       "1245  _2viQ_Qnc6_fgKR1W7-k1lbVURi8hVbMlQAMSOCSnyk     ThirdDegr3e   \n",
       "278           z12hvvki4xite3sjl04cfp34wxy0fr0qjgs  latisha garcia   \n",
       "593           z121i1eqppzph3eod04cixfgwknydnfzq3k  railn j sander   \n",
       "707   LneaDw26bFvv8RbyHRBDnA-4Bb1lhF9UlpzJf_5FkWM            이 정훈   \n",
       "1311            z13ax5sicvvxsx3lx23vuf45tye4etl1g      Kasia Hill   \n",
       "1302          z135drnwswvsgvkyq04cfjh4xpb3cn2hugg       Sam Klein   \n",
       "\n",
       "                            DATE  \\\n",
       "904   2015-05-27T09:24:10.239000   \n",
       "557                          NaN   \n",
       "1146  2013-09-09T17:34:07.052000   \n",
       "72    2015-05-25T03:02:02.615000   \n",
       "1245  2013-07-13T20:48:22.967000   \n",
       "278   2015-03-09T00:33:08.463000   \n",
       "593   2015-05-26T05:32:15.041000   \n",
       "707                          NaN   \n",
       "1311         2014-09-06T02:44:43   \n",
       "1302         2014-08-31T03:52:29   \n",
       "\n",
       "                                                CONTENT  CLASS  \n",
       "904                  i love this song thumsb up to you﻿      0  \n",
       "557                       WATCH MY VIDEOS AND SUBSCRIBE      1  \n",
       "1146  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...      1  \n",
       "72                                   I LOVE YOUR SONGS﻿      0  \n",
       "1245  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1  \n",
       "278        Check out this playlist on YouTube: I tried﻿      1  \n",
       "593   I guss this song is one of my worst fears in l...      0  \n",
       "707   This great Warning will happen soon. ,0\\nLneaD...      1  \n",
       "1311                   http://shhort.com/a?r=G8iX5cTKd﻿      1  \n",
       "1302  She named the tiger Kitty Purry  No, seriously...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_list = []\n",
    "for file_ in [os.path.join(DATA_DIR, file) for file in training_files if file.endswith(\".csv\")]:\n",
    "    df = pd.read_csv(file_, index_col=None, header=0)\n",
    "    training_df_list.append(df)\n",
    "\n",
    "training_df = pd.concat(training_df_list, axis = 0, ignore_index = True)\n",
    "training_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@chrisfotache/text-classification-in-python-pipelines-nlp-nltk-tf-idf-xgboost-and-more-b83451a327e0\n",
    "\n",
    "https://www.kaggle.com/abhikbanerjee/approaching-almost-any-nlp-problem-on-kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1956,)\n",
      "(1956,)\n"
     ]
    }
   ],
   "source": [
    "xall = training_df.CONTENT\n",
    "yall = training_df.CLASS\n",
    "print(xall.shape)\n",
    "print(yall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1760,)\n",
      "(196,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(\n",
    "    xall, \n",
    "    yall, \n",
    "    stratify=yall, \n",
    "    random_state=42, \n",
    "    test_size=0.1, \n",
    "    shuffle=True\n",
    ")\n",
    "print (xtrain.shape)\n",
    "print (xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1760x2129 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18636 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(\n",
    "    min_df=3,  \n",
    "    max_features=None,\n",
    "    strip_accents='unicode', \n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 3), \n",
    "    use_idf=1,\n",
    "    smooth_idf=1,\n",
    "    sublinear_tf=1,\n",
    "    stop_words = 'english'\n",
    ")\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)\n",
    "xtrain_tfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVD\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "# Initialize the standard scaler \n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "# We will use logistic regression here..\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('tfv', tfv),\n",
    "                         ('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('lr', lr_model)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svd__n_components' : [120, 180],\n",
    "              'lr__C': [0.1, 1.0, 10], \n",
    "              'lr__penalty': ['l1', 'l2']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   39.1s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfv', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=1,\n",
       "    ...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'svd__n_components': [120, 180], 'lr__C': [0.1, 1.0, 10], 'lr__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(\n",
    "    estimator=clf, \n",
    "    param_grid=param_grid, \n",
    "    verbose=10, \n",
    "    n_jobs=-1, \n",
    "    iid=True, \n",
    "    refit=True, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xall, yall)  # we can use the full data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.927\n",
      "Best parameters set:\n",
      "\tlr__C: 1.0\n",
      "\tlr__penalty: 'l2'\n",
      "\tsvd__n_components: 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_to_fs(model.best_estimator_, filename=\"model.pkl\", subdirectory=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Help me get 10000000 subscribers by tomorrow!<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />(Joking don&#39;t get butt hurt)  \\ufeff'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_.predict(\n",
    "    [\n",
    "        \"Check it out this free stuff!!!\",\n",
    "        \"I take issue with your characterization.\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
